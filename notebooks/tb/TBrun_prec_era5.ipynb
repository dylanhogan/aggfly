{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fe6546a-e5b1-4221-97ce-2fdc022de91c",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00cafd18-d708-4910-9fdf-5f997c67e74e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bearpark/.conda/envs/aggfly/lib/python3.8/site-packages/geopandas/_compat.py:112: UserWarning: The Shapely GEOS version (3.10.3-CAPI-1.16.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import ctypes\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "import aggfly\n",
    "from aggfly import regions, grid_weights, dataset\n",
    "from aggfly.aggregate import TemporalAggregator, SpatialAggregator\n",
    "\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask.cache import Cache\n",
    "\n",
    "# cache = Cache(10e9)  # Leverage two gigabytes of memory\n",
    "# cache.register()    # Turn cache on globally\n",
    "\n",
    "ProgressBar().register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b29ecda-a44c-46dd-911d-c9213cdaf734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file output name/path\n",
    "input_path  = \"/projects/OPPENHEIMER/tb/climate/\"\n",
    "output_path = \"/projects/OPPENHEIMER/tb/climate/aggregated/\"\n",
    "code        = \"/home/bearpark/Documents/aggfly/\"\n",
    "output_name = \"precip_monthly_polys\"\n",
    "varname     = \"prec\"\n",
    "csv = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abad076-923a-46d3-8e44-fc6d500fadac",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Define aggregation parameters\n",
    "\n",
    "These objects describe the spatial and temporal aggregation operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3721eca8-3636-44b2-aee2-e5a8c9457066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<aggfly.aggregate.temporal.TemporalAggregator at 0x14ccd9f38220>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open shapefile containing region features.\n",
    "georegions = regions.from_name('uk')\n",
    "\n",
    "# Years to aggregate\n",
    "years = np.arange(1994,2020)\n",
    "\n",
    "# Polynomials\n",
    "polys = [1,2,3,4,5,6,7,8]\n",
    "\n",
    "# This object aggregates cells within a region to the average across \n",
    "# cells, weighted by `weights`, which in this case are the area of the\n",
    "# cell and the share of the cell with corn crops.\n",
    "spatial = SpatialAggregator('avg')\n",
    "\n",
    "# This object covers aggregating hourly and daily data to the yearly \n",
    "# level\n",
    "daily = [TemporalAggregator(\n",
    "    'sum',\n",
    "    agg_from='hour',\n",
    "    agg_to='day') for p in polys]\n",
    "\n",
    "monthly = TemporalAggregator(\n",
    "    'sum', \n",
    "    agg_from='day',\n",
    "    agg_to='month')\n",
    "\n",
    "monthly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a432afa4-314d-4450-96ff-1618e747cb41",
   "metadata": {},
   "source": [
    "#### Calculate Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9516294e-8fef-4227-89ab-2959954c48e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open example climate dataset to calculate grid weights.\n",
    "clim = dataset.from_path(\n",
    "    f\"{input_path}tempPrecLand1951.zarr\", \n",
    "    'tp', \n",
    "    'zarr', \n",
    "    preprocess=dataset.preprocess_era5l)\n",
    "\n",
    "# Clip climate data to the US (raw data are global)\n",
    "clim.clip_data_to_georegions_extent(georegions)\n",
    "\n",
    "# Rechunk dataset to optimize multithreading\n",
    "clim.rechunk(-1)\n",
    "\n",
    "# Calculate area and crop layer weights.\n",
    "weights = grid_weights.from_objects(clim, georegions, crop=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7844ade2-0ef4-45cc-b0b7-80032763b0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bearpark/.conda/envs/aggfly/lib/python3.8/site-packages/pygeos/io.py:85: UserWarning: The shapely GEOS version (3.10.3-CAPI-1.16.1) is incompatible with the PyGEOS GEOS version (3.10.1-CAPI-1.16.0). Conversions between both will be slow\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Calculate the grid weights\n",
    "w = weights.weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff2bde1-d185-4967-b454-3a5793fb5872",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = w.chunk((-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7219a951-57b2-4fa4-b1ac-4165564f8071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_era5l_tp(array):\n",
    "    with dask.config.set(**{'array.slicing.split_large_chunks': False}):        \n",
    "        array.coords['longitude'] = (array.coords['longitude'] + 180) % 360 - 180\n",
    "        array = array.sortby(array.longitude)\n",
    "        array['year'] = array.time.dt.year\n",
    "        array['month'] = array.time.dt.month\n",
    "        array['day'] = array.time.dt.day\n",
    "        array['hour'] = array.time.dt.hour\n",
    "        array = array.set_index(time=(\"year\", \"month\", \"day\", \"hour\")).unstack('time')\n",
    "        # array = array - 273.15\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76e65ad-4bc1-4973-841e-bec474158a55",
   "metadata": {},
   "source": [
    "#### Run aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a73ba9-8783-4bca-989b-9dec5111ab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_era5l_agg(year, input_path):\n",
    "    # This function performs the actual aggregation for a single year, region.\n",
    "    # Note that this function runs \"lazily\", i.e., returns an object that is\n",
    "    # passed on to Dask for computation.\n",
    "    \n",
    "    clim = dataset.from_path(\n",
    "        f\"{input_path}tempPrecLand{year}.zarr\", \n",
    "        var = 'prec', \n",
    "        engine = 'zarr', \n",
    "        preprocess=dataset.preprocess_era5l_tp)\n",
    "\n",
    "    clim.clip_data_to_georegions_extent(georegions)\n",
    "\n",
    "    clim.rechunk(-1)\n",
    "\n",
    "    # # Temporal aggregation to gridcell by day\n",
    "    daily_list = [x.map_execute(clim) for x in daily]\n",
    "\n",
    "    # # Sum across days after taking the non-linear transformation\n",
    "    monthly_list = [monthly.map_execute(x) for x in daily_list]\n",
    "    \n",
    "    # # Spatial agregation\n",
    "    out_clim = [spatial.map_execute(x, w) for x in monthly_list]\n",
    "    \n",
    "    # Return only the dask dataframes from the Datset objects\n",
    "    return [x.da.data for x in out_clim]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a2c052-f593-4342-8834-02e054e9bc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('AGGREGATING YEARS')\n",
    "output_list = list()\n",
    "time_list = list()\n",
    "for year in years:\n",
    "    print(year)\n",
    "\n",
    "    # Start timing\n",
    "    start = time.time()\n",
    "    time_list.append(year)\n",
    "\n",
    "    # Aggregate this year, region & append to list\n",
    "    output_list.append(dask.compute(run_era5l_agg(year, input_path))[0])\n",
    "\n",
    "    # Report timing\n",
    "    stop = time.time()\n",
    "    duration = stop-start\n",
    "    print(round(duration/60,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac9bf17-3c28-4f6f-93f0-9399374ccb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('COMBINING OUTPUT')\n",
    "# Put everything together in one dataset\n",
    "\n",
    "d_list = list()\n",
    "for t in range(len(polys)):\n",
    "    y_list = list()\n",
    "    for y in range(len(years)):\n",
    "        y_list.append(xr.DataArray(\n",
    "            data = output_list[y][t],\n",
    "            dims = ['region', 'year', 'month'],\n",
    "            coords = dict(\n",
    "                region=('region', georegions.regions),\n",
    "                year = ('year', [years[y]]),\n",
    "                month = ('month', np.arange(1,13))\n",
    "            ),\n",
    "            # name = f'temp',\n",
    "            name = f'{varname}{polys[t]}'\n",
    "        ))\n",
    "    d_list.append(xr.concat(y_list, dim='year'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e17e7e3-07aa-483c-ae43-6ef0813aae1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "ds = xr.combine_by_coords(d_list)    \n",
    "ds = ds.to_dataframe()\n",
    "ds = ds.reset_index(level=['region', 'year', 'month'])\n",
    "ds = ds.rename(columns={'region':'id'})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749bff77-7f38-4411-9aec-af70ab7b5775",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_csv(os.path.join(output_path, output_name+'.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aggfly [~/.conda/envs/aggfly/]",
   "language": "python",
   "name": "conda_aggfly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
